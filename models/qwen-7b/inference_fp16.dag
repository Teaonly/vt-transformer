1e-06                   "RMS_EPS"               !
10000.0                 "ROTARY_BASE"           !
2.5                     "TEMPERATURE"           !

151936                  "VOCAB_SIZE"            !
4096                    "HIDDEN_SIZE"           !
11008                   "INTERMEDIATE_SIZE"     !
32                      "HEADS_NUM"             !
128                     "HEAD_HIDDEN"           !

2                       "MAX_BATCH"             !
1526                    "MAX_CONTEXT"           !
"./fp16/"               "G_PATH"                !

%def create_input_weight
    $DEVICE !

    "VOCAB_SIZE" @ "HIDDEN_SIZE" @ 2 $DEVICE @ "fp16" op.create "wte.weight"  !

    $DEVICE !!
%end

%def create_output_weight
    $DEVICE !

    1 1 "HIDDEN_SIZE" @ 3 $DEVICE @ "fp16"  op.create  "ln_f.weight"  !
    "VOCAB_SIZE" @ "HIDDEN_SIZE" @ 2 $DEVICE @ "fp16" op.create "lm_head.weight" !

    $DEVICE !!
%end

%def create_layer_weight
    $L !
    $DEVICE !

    (1 1 "HIDDEN_SIZE" @  3 $DEVICE @ "fp16")  op.create  $L @ "ln_1.weight" | !
    (1 1 "HIDDEN_SIZE" @  3 $DEVICE @ "fp16")  op.create  $L @ "ln_2.weight"  | !

    ("HIDDEN_SIZE" @ 3 * "HIDDEN_SIZE" @ 2 $DEVICE @  "fp16" )  op.create  $L @  "attn.qkv_proj.weight" | !
    ("HIDDEN_SIZE" @ 3 *                 1 $DEVICE @  "fp16" )  op.create  $L @  "attn.qkv_proj.bias" | !
    ;
    ; dummy split to three tensors, 4096 * 4096 = 16777216
    ;
    ($L @ "attn.qkv_proj.weight" | @ 0                             "HIDDEN_SIZE" @ dup 2 op.view)  $L @  "query.weight" | !
    ($L @ "attn.qkv_proj.weight" | @ ("HIDDEN_SIZE" @ dup *)       "HIDDEN_SIZE" @ dup 2 op.view)  $L @  "key.weight" | !
    ($L @ "attn.qkv_proj.weight" | @ ("HIDDEN_SIZE" @ dup * 2 *)   "HIDDEN_SIZE" @ dup 2 op.view)  $L @  "value.weight" | !
    
    ($L @ "attn.qkv_proj.bias" | @ 0                               "HIDDEN_SIZE" @ 1 op.view)  $L @  "query.bias" | !
    ($L @ "attn.qkv_proj.bias" | @ ("HIDDEN_SIZE" @ )              "HIDDEN_SIZE" @ 1 op.view)  $L @  "key.bias" | !
    ($L @ "attn.qkv_proj.bias" | @ ("HIDDEN_SIZE" @ 2 *)           "HIDDEN_SIZE" @ 1 op.view)  $L @  "value.bias" | !
    
    ("HIDDEN_SIZE" @  "HIDDEN_SIZE" @ 2 $DEVICE @  "fp16")  op.create   $L @ "attn.c_proj.weight" |  !

    ("INTERMEDIATE_SIZE" @  "HIDDEN_SIZE" @ 2 $DEVICE @  "fp16")  op.create  $L @  "mlp.w1.weight"  | !
    ("INTERMEDIATE_SIZE" @  "HIDDEN_SIZE" @ 2 $DEVICE @  "fp16")  op.create  $L @  "mlp.w2.weight"  | !
    ("HIDDEN_SIZE" @  "INTERMEDIATE_SIZE" @ 2 $DEVICE @  "fp16")  op.create  $L @  "mlp.c_proj.weight" | !

    $L !!
    $DEVICE !!
%end

%def load_input_weight
    "Loading input weight..." ? 
    
    $weights_path ! 

    "wte.weight" @
    $weights_path @ "wte.fp16" |
    io.load

    $weights_path !!

    "Loaded input weight." ?
%end

%def load_output_weight
    "Loading output weight..." ? 
    
    $weights_path ! 
    
    "ln_f.weight" @
    $weights_path @ "ln_f.fp16"  |
    io.load

    "lm_head.weight" @
    $weights_path @ "lm_head.fp16"  |
    io.load

    $weights_path !!

    "Loaded output weight." ?
%end

%def load_layer_weight
    $L !
    $weights_path ! 
    
    "Loading... " $weights_path @ | ?
    
    $L @ "ln_1.weight"                     | @ $weights_path @  "ln_1.weight.fp16"                | io.load
    $L @ "ln_2.weight"                     | @ $weights_path @  "ln_2.weight.fp16"                | io.load
    $L @ "attn.qkv_proj.weight"            | @ $weights_path @  "attn.c_attn.weight.fp16"         | io.load
    $L @ "attn.qkv_proj.bias"              | @ $weights_path @  "attn.c_attn.bias.fp16"           | io.load
    $L @ "attn.c_proj.weight"              | @ $weights_path @  "attn.c_proj.weight.fp16"         | io.load
    $L @ "mlp.w1.weight"                   | @ $weights_path @  "mlp.w1.weight.fp16"              | io.load
    $L @ "mlp.w2.weight"                   | @ $weights_path @  "mlp.w2.weight.fp16"              | io.load
    $L @ "mlp.c_proj.weight"               | @ $weights_path @  "mlp.c_proj.weight.fp16"          | io.load
    
    "Loaded " $weights_path @ | ?
    
    $L !!
    $weights_path !!
%end

%def sync_layer_clone
    $L !

    $L @ "ln_1.weight"                        | @ "ln_1.weight"                       !
    $L @ "ln_2.weight"                        | @ "ln_2.weight"                       !
    $L @ "attn.qkv_proj.weight"               | @ "attn.qkv_proj.weight"              !
    $L @ "attn.qkv_proj.bias"                 | @ "attn.qkv_proj.bias"                !
    $L @ "attn.c_proj.weight"                 | @ "attn.c_proj.weight"                !
    $L @ "mlp.w1.weight"                      | @ "mlp.w1.weight"                     !
    $L @ "mlp.w2.weight"                      | @ "mlp.w2.weight"                     !
    $L @ "mlp.c_proj.weight"                  | @ "mlp.c_proj.weight"                 !

    ;
    ; dummy split to three tensors, 4096 * 4096 = 16777216
    ;
    ("attn.qkv_proj.weight" @ 0                             "HIDDEN_SIZE" @ dup 2 op.view)  "query.weight"  !
    ("attn.qkv_proj.weight" @ ("HIDDEN_SIZE" @ dup *)       "HIDDEN_SIZE" @ dup 2 op.view)  "key.weight"    !
    ("attn.qkv_proj.weight" @ ("HIDDEN_SIZE" @ dup * 2 *)   "HIDDEN_SIZE" @ dup 2 op.view)  "value.weight"  !
   
    ("attn.qkv_proj.bias" @ 0                             "HIDDEN_SIZE" @ 1 op.view)  "query.bias"  !
    ("attn.qkv_proj.bias" @ ("HIDDEN_SIZE" @ )            "HIDDEN_SIZE" @ 1 op.view)  "key.bias"    !
    ("attn.qkv_proj.bias" @ ("HIDDEN_SIZE" @ 2 *)         "HIDDEN_SIZE" @ 1 op.view)  "value.bias"  !

    $L !!
%end

%def init_internal_variable
    $DEVICE !

    ;; activity memory
    0.20 1024 1024 1024 * * * 1 $DEVICE @  "fp16" op.create  "_var_"  !
    
    ;; kv cached memroy
    32 2 1600 "HIDDEN_SIZE" @ 4 $DEVICE @  "fp16" op.create dup "_kcache_"  !
    32 2 1600 "HIDDEN_SIZE" @ 4 $DEVICE @  "fp16" op.create dup "_vcache_"  !
    nn.ezkv_init "cache_man" !

    "MAX_CONTEXT" @ "MAX_BATCH" @ * dup dup dup 
    1 "host" "int"  op.create  "_ids_"     !
    1 "host" "int"  op.create  "_mask_"    !
    1 $DEVICE @  "int"  op.create  "_ids"      !
    1 $DEVICE @  "int"  op.create  "_mask"     !
    1024 1 $DEVICE @  "int" op.create "_position" !
    
    10000 "HEAD_HIDDEN" @ 2 3 $DEVICE @  "float" op.create dup 
    "ROTARY_BASE" @ op.rotary_cache 
    "rotary_cache" !

    $DEVICE !!
%end

%def gpu_init
    "dcu"       init_internal_variable
    "host"      create_input_weight
    "dcu"       create_output_weight
    
    "dcu"    "L0."   create_layer_weight 
    "dcu"    "L1."   create_layer_weight 
    "dcu"    "L2."   create_layer_weight 
    "dcu"    "L3."   create_layer_weight 
    "dcu"    "L4."   create_layer_weight
    "dcu"    "L5."   create_layer_weight 
    "dcu"    "L6."   create_layer_weight 
    "dcu"    "L7."   create_layer_weight 
    "dcu"    "L8."   create_layer_weight 
    "dcu"    "L9."   create_layer_weight
    "dcu"    "L10."  create_layer_weight
    "dcu"    "L11."  create_layer_weight
    "dcu"    "L12."  create_layer_weight
    "dcu"    "L13."  create_layer_weight
    "dcu"    "L14."  create_layer_weight
    "dcu"    "L15."  create_layer_weight
    "dcu"    "L16."   create_layer_weight 
    "dcu"    "L17."   create_layer_weight 
    "dcu"    "L18."   create_layer_weight 
    "dcu"    "L19."   create_layer_weight 
    "dcu"    "L20."   create_layer_weight
    "dcu"    "L21."   create_layer_weight 
    "dcu"    "L22."   create_layer_weight 
    "dcu"    "L23."   create_layer_weight 
    "dcu"    "L24."   create_layer_weight 
    "dcu"    "L25."   create_layer_weight
    "dcu"    "L26."   create_layer_weight
    "dcu"    "L27."   create_layer_weight
    "dcu"    "L28."   create_layer_weight
    "dcu"    "L29."   create_layer_weight
    "dcu"    "L30."   create_layer_weight
    "dcu"    "L31."   create_layer_weight
%end

%def gpu_main
    "main...." ?
%end

